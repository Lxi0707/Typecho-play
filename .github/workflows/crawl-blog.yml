name: Auto Crawl Blog - Precise Visits

on:
  schedule:
    # 每天UTC时间3点运行 (北京时间11点)
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      visits:
        description: 'Number of visits to simulate'
        required: false
        default: '1000'
        type: string
      max_pages:
        description: 'Max pages to crawl for articles'
        required: false
        default: '10'
        type: string

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install aiohttp beautifulsoup4
    
    - name: Run precise crawler
      env:
        TG_BOT_TOKEN: ${{ secrets.TG_BOT_TOKEN }}
        TG_CHAT_ID: ${{ secrets.TG_CHAT_ID }}
      run: |
        python precise_crawler.py \
          --base-url "https://www.207725.xyz" \
          --visits ${{ github.event.inputs.visits || 1000 }} \
          --max-pages ${{ github.event.inputs.max_pages || 10 }} \
          --tg-bot-token "$TG_BOT_TOKEN" \
          --tg-chat-id "$TG_CHAT_ID" \
          --max-concurrent 5
