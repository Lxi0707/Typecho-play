#!/usr/bin/env python3
import asyncio
import aiohttp
import random
import argparse
from datetime import datetime
import logging
import os
from typing import List, Dict, Tuple, Optional

# é…ç½®éƒ¨åˆ†
BLOG_URL = "https://www.207725.xyz"
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")  # ä»ç¯å¢ƒå˜é‡è·å–
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")      # ä»ç¯å¢ƒå˜é‡è·å–
POSTS_FILE = "posts.txt"  # å¿…åˆ·URLåˆ—è¡¨æ–‡ä»¶

# ç”¨æˆ·ä»£ç†åˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (iPad; CPU OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1",
]

# åˆå§‹åŒ–æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BlogVisitor:
    def __init__(self, total_visits: int):
        self.total_visits = total_visits
        self.success_count = 0
        self.failure_count = 0
        self.required_success = 0
        self.required_failure = 0
        self.visited_urls: Dict[str, int] = {}
        self.required_urls: Dict[str, int] = {}
        self.session = None
        self.article_urls = []  # å­˜å‚¨è·å–åˆ°çš„æ–‡ç« URL
        self.required_article_urls = []  # å­˜å‚¨å¿…åˆ·çš„æ–‡ç« URL

    async def load_required_urls(self) -> bool:
        """ä»posts.txtåŠ è½½å¿…åˆ·URLåˆ—è¡¨"""
        try:
            if not os.path.exists(POSTS_FILE):
                logger.warning(f"æœªæ‰¾åˆ°å¿…åˆ·URLæ–‡ä»¶ {POSTS_FILE}")
                return False
                
            with open(POSTS_FILE, 'r', encoding='utf-8') as f:
                urls = [line.strip() for line in f if line.strip()]
                self.required_article_urls = [url for url in urls if url.startswith(('http://', 'https://'))]
                
            if not self.required_article_urls:
                logger.warning(f"å¿…åˆ·URLæ–‡ä»¶ {POSTS_FILE} ä¸­æ²¡æœ‰æœ‰æ•ˆçš„URL")
                return False
                
            logger.info(f"ä» {POSTS_FILE} åŠ è½½äº† {len(self.required_article_urls)} ä¸ªå¿…åˆ·URL")
            return True
        except Exception as e:
            logger.error(f"åŠ è½½å¿…åˆ·URLæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False

    async def fetch_article_urls(self) -> List[str]:
        """ä»åšå®¢é¦–é¡µè·å–æ–‡ç« é“¾æ¥"""
        try:
            headers = {
                "User-Agent": random.choice(USER_AGENTS),
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(BLOG_URL, headers=headers) as response:
                    if response.status == 200:
                        text = await response.text()
                        # ç®€å•çš„è§£æé€»è¾‘ï¼Œæ ¹æ®Typechoçš„ç»“æ„è·å–æ–‡ç« é“¾æ¥
                        from bs4 import BeautifulSoup
                        soup = BeautifulSoup(text, 'html.parser')
                        article_links = []
                        
                        # æŸ¥æ‰¾æ–‡ç« é“¾æ¥ - æ ¹æ®Typechoçš„ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
                        for link in soup.select('a[href*="/archives/"]'):
                            href = link.get('href')
                            if href and href.startswith(BLOG_URL) and href not in article_links:
                                article_links.append(href)
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ç« é“¾æ¥ï¼Œä½¿ç”¨é»˜è®¤çš„å‡ ä¸ª
                        if not article_links:
                            article_links = [
                                f"{BLOG_URL}/index.php/archives/13/",
                                f"{BLOG_URL}/index.php/archives/5/",
                                f"{BLOG_URL}/index.php/archives/1/",
                            ]
                        
                        return article_links
                    else:
                        logger.warning(f"è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return [
                            f"{BLOG_URL}/index.php/archives/13/",
                            f"{BLOG_URL}/index.php/archives/5/",
                            f"{BLOG_URL}/index.php/archives/1/",
                        ]
        except Exception as e:
            logger.error(f"è·å–æ–‡ç« åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return [
                f"{BLOG_URL}/index.php/archives/13/",
                f"{BLOG_URL}/index.php/archives/5/",
                f"{BLOG_URL}/index.php/archives/1/",
            ]

    async def visit_url(self, url: str, is_required: bool = False):
        """è®¿é—®å•ä¸ªURL"""
        try:
            headers = {
                "User-Agent": random.choice(USER_AGENTS),
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
                "Referer": BLOG_URL,
                "DNT": "1",  # Do Not Track
            }
            
            # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
            await asyncio.sleep(random.uniform(0.5, 3.0))
            
            async with self.session.get(url, headers=headers) as response:
                if response.status == 200:
                    if is_required:
                        self.required_success += 1
                        self.required_urls[url] = self.required_urls.get(url, 0) + 1
                    else:
                        self.success_count += 1
                        self.visited_urls[url] = self.visited_urls.get(url, 0) + 1
                    logger.info(f"æˆåŠŸè®¿é—®: {url}")
                else:
                    if is_required:
                        self.required_failure += 1
                    else:
                        self.failure_count += 1
                    logger.warning(f"è®¿é—®å¤±è´¥: {url}, çŠ¶æ€ç : {response.status}")
        except Exception as e:
            if is_required:
                self.required_failure += 1
            else:
                self.failure_count += 1
            logger.error(f"è®¿é—® {url} æ—¶å‡ºé”™: {str(e)}")

    async def run_required_visits(self):
        """æ‰§è¡Œå¿…åˆ·URLçš„è®¿é—®"""
        if not self.required_article_urls:
            return
            
        logger.info(f"å¼€å§‹è®¿é—® {len(self.required_article_urls)} ä¸ªå¿…åˆ·URL")
        
        tasks = []
        async with aiohttp.ClientSession() as self.session:
            for url in self.required_article_urls:
                tasks.append(self.visit_url(url, is_required=True))
            
            await asyncio.gather(*tasks)
        
        logger.info(f"å¿…åˆ·URLè®¿é—®å®Œæˆ: æˆåŠŸ {self.required_success}, å¤±è´¥ {self.required_failure}")

    async def run_normal_visits(self):
        """æ‰§è¡Œæ™®é€šè®¿é—®ä»»åŠ¡"""
        if self.total_visits <= 0:
            return
            
        logger.info(f"å¼€å§‹æ¨¡æ‹Ÿè®¿é—®ï¼Œæ€»æ¬¡æ•°: {self.total_visits}")
        
        # è·å–æ–‡ç« URLåˆ—è¡¨
        self.article_urls = await self.fetch_article_urls()
        if not self.article_urls:
            logger.error("æ— æ³•è·å–æ–‡ç« URLåˆ—è¡¨ï¼Œè·³è¿‡æ™®é€šè®¿é—®")
            return
        
        logger.info(f"è·å–åˆ° {len(self.article_urls)} ç¯‡æ–‡ç« ")
        
        # è®¡ç®—æ¯ç¯‡æ–‡ç« çš„è®¿é—®æ¬¡æ•°ï¼ˆå‡åŒ€åˆ†é…ï¼‰
        visits_per_article = self.total_visits // len(self.article_urls)
        remaining_visits = self.total_visits % len(self.article_urls)
        
        # åˆ›å»ºè®¿é—®ä»»åŠ¡åˆ—è¡¨
        tasks = []
        async with aiohttp.ClientSession() as self.session:
            for i, url in enumerate(self.article_urls):
                # åˆ†é…è®¿é—®æ¬¡æ•°
                visits = visits_per_article + (1 if i < remaining_visits else 0)
                for _ in range(visits):
                    tasks.append(self.visit_url(url))
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è®¿é—®ä»»åŠ¡
            await asyncio.gather(*tasks)
        
        logger.info(f"æ™®é€šè®¿é—®å®Œæˆ: æˆåŠŸ {self.success_count}, å¤±è´¥ {self.failure_count}")

    async def run_visits(self):
        """æ‰§è¡Œè®¿é—®ä»»åŠ¡"""
        start_time = datetime.now()
        
        # åŠ è½½å¿…åˆ·URL
        await self.load_required_urls()
        
        # å…ˆæ‰§è¡Œå¿…åˆ·URLè®¿é—®
        await self.run_required_visits()
        
        # å†æ‰§è¡Œæ™®é€šè®¿é—®
        await self.run_normal_visits()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        total_requests = self.required_success + self.required_failure + self.success_count + self.failure_count
        requests_per_second = total_requests / duration if duration > 0 else 0
        
        # å‘é€é€šçŸ¥
        await self.send_statistics(start_time, end_time, duration, requests_per_second)
    
    async def send_statistics(self, start_time: datetime, end_time: datetime, duration: float, rps: float):
        """å‘é€ç»Ÿè®¡ä¿¡æ¯åˆ°Telegram"""
        message = (
            "ğŸ“Š åšå®¢è®¿é—®æ¨¡æ‹ŸæŠ¥å‘Š\n\n"
            f"â±ï¸ å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"â±ï¸ ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"â³ æ€»è€—æ—¶: {duration:.2f} ç§’\n"
            f"ğŸš€ æ€»è¯·æ±‚æ¬¡æ•°: {self.required_success + self.required_failure + self.success_count + self.failure_count}\n\n"
            "ğŸ”´ å¿…åˆ·URLç»Ÿè®¡:\n"
            f"  âœ… æˆåŠŸ: {self.required_success}\n"
            f"  âŒ å¤±è´¥: {self.required_failure}\n\n"
            "ğŸŸ¢ æ™®é€šè®¿é—®ç»Ÿè®¡:\n"
            f"  ğŸ¯ ç›®æ ‡æ¬¡æ•°: {self.total_visits}\n"
            f"  âœ… æˆåŠŸ: {self.success_count}\n"
            f"  âŒ å¤±è´¥: {self.failure_count}\n"
            f"  ğŸ“ˆ å¹³å‡é€Ÿåº¦: {rps:.2f} æ¬¡/ç§’\n\n"
        )
        
        # æ·»åŠ å¿…åˆ·URLçš„è®¿é—®ç»Ÿè®¡
        if self.required_urls:
            message += "ğŸ“Œ å¿…åˆ·URLè®¿é—®åˆ†å¸ƒ:\n"
            for url, count in self.required_urls.items():
                display_url = url.replace(BLOG_URL, "")
                message += f"  - {display_url}: {count} æ¬¡\n"
            message += "\n"
        
        # æ·»åŠ æ™®é€šURLçš„è®¿é—®ç»Ÿè®¡
        if self.visited_urls:
            message += "ğŸ“ æ™®é€šURLè®¿é—®åˆ†å¸ƒ:\n"
            for url, count in self.visited_urls.items():
                display_url = url.replace(BLOG_URL, "")
                message += f"  - {display_url}: {count} æ¬¡\n"
        
        # æ·»åŠ æ€»ç»“
        message += f"\nğŸŒ åšå®¢åœ°å€: {BLOG_URL}"
        
        await self.send_notification(message)
    
    async def send_notification(self, message: str):
        """é€šè¿‡Telegram botå‘é€é€šçŸ¥"""
        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
            logger.warning("æœªé…ç½®Telegram bot tokenæˆ–chat IDï¼Œè·³è¿‡é€šçŸ¥å‘é€")
            return
            
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"å‘é€Telegramé€šçŸ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, å“åº”: {error_text}")
                    else:
                        logger.info("Telegramé€šçŸ¥å‘é€æˆåŠŸ")
        except Exception as e:
            logger.error(f"å‘é€Telegramé€šçŸ¥æ—¶å‡ºé”™: {str(e)}")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Typechoåšå®¢è®¿é—®æ¨¡æ‹Ÿå™¨")
    parser.add_argument(
        "-n", "--visits",
        type=int,
        default=100,
        help="æ™®é€šè®¿é—®æ¬¡æ•°(å¿…åˆ·URLä¸è®¡å…¥æ­¤æ•°é‡)ï¼Œé»˜è®¤ä¸º100",
    )
    return parser.parse_args()

async def main():
    args = parse_args()
    visitor = BlogVisitor(args.visits)
    await visitor.run_visits()

if __name__ == "__main__":
    asyncio.run(main())
